{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This Function searches for the word Ethenticity.\n",
    "#The page gettyimage usually uses the word ethnicity\n",
    "#to for describing the ethnicity of a person in the image.\n",
    "#If it finds it it returns true.\n",
    "\n",
    "def is_ethnicity(given_tag):\n",
    "    if 'Ethnicity' in given_tag:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The demonyms.csv have the list of word describing nationality \n",
    "#of people. If it finds these words in the tag, it returns true.\n",
    "\n",
    "nationality_list = pd.read_csv('demonyms.csv', header=None)[0]\n",
    "\n",
    "def is_nationality(given_tag, nationality = nationality_list):\n",
    "    if any(word in given_tag for word in nationality):\n",
    "        return True\n",
    "    else:   \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Few tags are found in the image tags that denotes the Gender of\n",
    "#the person. This function tries to find these word and if it finds\n",
    "#the words it returns true.\n",
    "\n",
    "def is_gender(given_tag):\n",
    "    gender_words = ('Men', 'Man', 'Boy', 'Boys' 'Males', 'Male', \n",
    "                    'Girl', 'Girls', 'Women', 'Woman', 'Female', \n",
    "                    'Females')\n",
    "    \n",
    "    if any(word in given_tag for word in gender_words):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Few tags are found in the image tags that denotes the Maturity of\n",
    "#the person. This function tries to find these word and if it finds\n",
    "#the words it returns true.\n",
    "\n",
    "def is_maturity(given_tag):\n",
    "    maturity_words = ('Young', 'Old', 'Adult', 'Child', 'Mature')\n",
    "    \n",
    "    if any(word in given_tag for word in maturity_words):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function detects the tag which indicstes ethnicity, nationality, \n",
    "#gender, maturity and returns a dictionary cointining a list of these.\n",
    "\n",
    "def filter_tags(tags):\n",
    "    \n",
    "    ethnicity = []\n",
    "    nationality = []\n",
    "    gender = []\n",
    "    maturity = []\n",
    "    \n",
    "    for tag in tags:\n",
    "        if is_gender(tag): \n",
    "            gender.append(tag)\n",
    "        \n",
    "        if is_maturity(tag):\n",
    "            maturity.append(tag)\n",
    "        \n",
    "        #Same word can describe both Ethnicity and Nationality but \n",
    "        #Name tag does not. So, if it is describing Ethnicity then\n",
    "        #it is not describing Nationality.\n",
    "        \n",
    "        if is_ethnicity(tag): \n",
    "            ethnicity.append(tag.replace(\" Ethnicity\", \"\"))\n",
    "        elif is_nationality(tag):\n",
    "            nationality.append(tag)\n",
    "            \n",
    "    return {'Ethnicity': ethnicity, 'Nationality': nationality, \n",
    "                   'Gender': gender, 'Maturity': maturity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It takes the url for the page that has the tags and extracts the tags and\n",
    "#uses fliter tag to catagorize it.\n",
    "\n",
    "def get_photo_tags(image_page_url):\n",
    "    tag_list = []\n",
    "    \n",
    "    image_page = requests.get(image_page_url).content\n",
    "    \n",
    "    #It searches for all the HTML tags with class \"keyword\" and creates \n",
    "    #a tag list\n",
    "    html_image_page = BeautifulSoup(image_page,'html.parser')\n",
    "    \n",
    "    for image_tag in html_image_page.find_all(class_ = 'keyword'):\n",
    "        tag_list.append(image_tag.get_text())\n",
    "        \n",
    "    return filter_tags(tag_list) #It returns dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This Function extracts Image name and Image URL from a Image Tag\n",
    "def extract_image_info(image_extracted_data):\n",
    "    \n",
    "    image_page_start = \"https://www.gettyimages.in/detail/photo/\"\n",
    "    image_link = \"https://media.gettyimages.com/photos/\"\n",
    "    image_page_tag = \"-royalty-free-image/\"\n",
    "    \n",
    "    #Url of the image and the URL of the page cointaning tags of the image\n",
    "    #are determined.\n",
    "    image_url = image_extracted_data['src'].replace('?', \" \").split()[0]\n",
    "    image_temp_url = image_url.replace(image_link, image_page_start)\n",
    "    tag_page_url = image_temp_url.replace('-id', image_page_tag)\n",
    "        \n",
    "    image_name = image_extracted_data['alt'] #Image Name is being obtained\n",
    "    \n",
    "    image_information = {'Image Name': image_name, 'Image URL': image_url}\n",
    "    \n",
    "    image_tag = get_photo_tags(tag_page_url) #Filtered Tags are obtained\n",
    "    image_information.update(image_tag) #and added to the dictionary\n",
    "    \n",
    "    return image_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It checks if a folder named in the argument exists, if not then creates\n",
    "#it.\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    file_location = os.getcwd() + \"/\" + folder_name\n",
    "    if not os.path.isdir(file_location):\n",
    "        os.makedirs(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function ask input from user if theywant to download the Images scrapped\n",
    "#or just save the URL of the picture.\n",
    "\n",
    "def image_download_choice():\n",
    "    while(True):\n",
    "        input_message = \"Do You Want To Download Image Or URL (I/U) : \"\n",
    "        input_option = input(input_message)\n",
    "    \n",
    "        if ((input_option == 'U')|(input_option == 'u')):\n",
    "            return False\n",
    "        elif ((input_option == 'I')|(input_option == 'i')):\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Wrong Option Try Again\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function saves the image in the url and with the name that is\n",
    "#present in the argument dictionary image if user want to save it.\n",
    "\n",
    "def save_image(image, download_option):\n",
    "    if download_option:\n",
    "        img = requests.get(image['Image URL'])\n",
    "        \n",
    "        if img.status_code == 200:\n",
    "            create_folder(\"data/img/\")\n",
    "        \n",
    "            relative_image_location = \"/data/img/\"+ image['Image Name']\n",
    "            image_file_name = os.getcwd() + relative_image_location\n",
    "\n",
    "            with open(image_file_name  + '.jpg' , 'wb') as file:\n",
    "                file.write(img.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function returns a dataframe with the template required to store data.\n",
    "def get_data_frame():\n",
    "    columns_name = ['Image Name', 'Ethnicity', 'Nationality',\n",
    "                    'Gender', 'Maturity', 'Image URL']\n",
    "    \n",
    "    return pd.DataFrame(columns = columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is a generator which yields a list of information\n",
    "#in a html tag 'articles'. Every time it yields a result it moves\n",
    "#on to the next page of the search results and yields it in required\n",
    "#form untill the required number of pages a yielded.\n",
    "\n",
    "def get_search_page(search_text, number_of_image):\n",
    "    \n",
    "    create_folder(\"data\")\n",
    "    number_of_page = int(number_of_image/60) + 1\n",
    "    page_no = 1 #keeps track number of page currently in.\n",
    "            \n",
    "    search_url = \"https://www.gettyimages.in/photos/\" #Initial part of the url\n",
    "    page_tag = '?page=' #this should be added to the search url if it is fetching\n",
    "    #image beyond 1st page.\n",
    "    \n",
    "    for words in list(search_text.split()):\n",
    "        search_url = search_url + words.lower() + '-'\n",
    "    \n",
    "    search_url = search_url[:-1]\n",
    "    search_link = search_url #Url For the 1st page\n",
    "\n",
    "    while(page_no <= number_of_page):\n",
    "        html_page = requests.get(search_link).content\n",
    "        web_page = BeautifulSoup(webpage,'html.parser')\n",
    "        \n",
    "        page_no += 1\n",
    "        #Url for the next page :\n",
    "        search_link = search_url + page_tag + str(page_no)\n",
    "        \n",
    "        yield web_page.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It extracts all the image data present in the search result page\n",
    "\n",
    "def get_page_data(search_webpage, download_option):    \n",
    "    page_image_data = get_data_frame()\n",
    "    \n",
    "    for image_data in search_webpage: #Getting the individual image info\n",
    "        image_extracted_data  = image_data.find('img')\n",
    "        \n",
    "        image_information = extract_image_info(image_extracted_data)\n",
    "        save_image(image_information, download_option)\n",
    "        \n",
    "        #The dictionary tags which does not have any data are removed.\n",
    "        for tag_name, tag_element in image_information.items():\n",
    "            if not tag_element:\n",
    "                del image_information[tag_name] \n",
    "        \n",
    "        page_image_data = page_image_data.append(image_information,\n",
    "                                                 ignore_index=True)\n",
    "    \n",
    "    return page_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function utilizes multicore processing to process data where each\n",
    "#core processes a search result page. Here core_use is equal to number \n",
    "#of core that will be used and the number of search result page that will\n",
    "#be processed\n",
    "\n",
    "def multiprocessor_scrapping(search_page, core_use, download_option):\n",
    "    image_data = get_data_frame()\n",
    "    get_page_data_option  = functools.partial(get_page_data,\n",
    "                                              download_option = download_option)\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        with multiprocessing.Pool(processes=core_use) as pool:\n",
    "            search_pages = [next(search_page) for _ in range(core_use)]\n",
    "            result = pool.map(get_page_data_option, search_pages)\n",
    "    \n",
    "    #Storing the search result into dataframes\n",
    "    for page_image_data in result:\n",
    "        result_image_data = image_data.append(page_image_data, \n",
    "                                              ignore_index=True)\n",
    "                    \n",
    "    return result_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_page():\n",
    "    keyword = str(input(\"\\nEnter Keyword: \"))\n",
    "    pic_number = int(input(\"\\nEnter The Number of Picture You Want To Download : \"))\n",
    "    download_option = image_download_choice()\n",
    "    \n",
    "    sys.setrecursionlimit(1000000000)\n",
    "    processes = multiprocessing.cpu_count()\n",
    "    \n",
    "    image_data = get_data_frame()\n",
    "    searched_page = get_search_page(keyword, pic_number)\n",
    "        \n",
    "    number_of_page = int(pic_number/60) + 1\n",
    "    full_process = int(number_of_page/processes)\n",
    "    incomplete_process = number_of_page - number_of_full_process*processes\n",
    "        \n",
    "    for _ in range(full_process):\n",
    "        result_image_data = multiprocessor_scrapping(searched_page,\n",
    "                                                     processes, download_option)   \n",
    "        image_data = image_data.append(result_image_data, ignore_index=True)\n",
    "                    \n",
    "    result_image_data = multiprocessor_scrapping(searched_page,\n",
    "                                                 incomplete_process, download_option)\n",
    "    image_data = image_data.append(result_image_data, ignore_index=True)\n",
    "                    \n",
    "    image_data.to_csv('data/image_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrap_page()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
